{
  "comments": [
    {
      "key": {
        "uuid": "27ccdd40_e3877b62",
        "filename": "src/vnet/session/session.c",
        "patchSetId": 10
      },
      "lineNbr": 486,
      "author": {
        "id": 193
      },
      "writtenOn": "2020-02-01T23:35:44Z",
      "side": 1,
      "message": "After thinking a bit more about this, the algorithm doesn\u0027t feel right. If there\u0027s a difference in speed between the consumer and the producer, with the consumer being faster, after each write utilization will be minimal. In other words, all this checks will have no effect apart from consuming cpu. Same for tx as a fast producer will always keep the fifo full (more lower).\n\nI believe we should be doing the tuning periodically and tracking just how much data was enqueued/dequeued per period. Probably the best would be per rtt but then the protocols need to be aware of the rtt (udp is not) and/or the tuning might have to be driven by those protocols. Not sure about the best option at this point ... \n\nConsidering that the fifos have an overhead that\u0027s only slightly higher than the amount of data enqueued, i.e., fifo size can be 2MB but only a fraction of that could be allocated, what type of tuning is actually needed short term? Or what\u0027s the minimal algorithm that we need to merge and start testing, while we work on improving this? \n\nI guess we have 2 options: \n- leave the patch mostly as is, but only handle tuning when the custom tuning flag is set, i.e., not do tuning for the general case.\n- have the proxy app do the tuning on rx notification and merge the patch except the session_fifo_tuning changes. \n\nBoth of these are focused on rx fifo tuning, but as far as I can tell, that\u0027s enough for the proxy case. Keep in mind though that we should not constantly check the status of the segment after each rx event. \n\nDid I miss something?\n\nOnce we get the basic features in and testing can start, we can focus on doing more optimizations.",
      "range": {
        "startLine": 486,
        "startChar": 6,
        "endLine": 486,
        "endChar": 25
      },
      "revId": "ce0ca25a6c3139845ad45afd8af6bf130a9e3974",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "7f39afbb_af228ec4",
        "filename": "src/vnet/session/session.c",
        "patchSetId": 10
      },
      "lineNbr": 486,
      "author": {
        "id": 1561
      },
      "writtenOn": "2020-02-03T04:36:47Z",
      "side": 1,
      "message": "Hi Florin,\n\nThanks for the inspection/analysis.\n\nI suppose the option-1 means just removing default-tuning-logic. Correct me if I\u0027m wrong.\n\nOn the other hand, if my recognition is correct, the frequency of RX-notification looks less frequent than that of session_fifo_tuning, right? If so, the option-2 seems better for now from the view of performance impact, and it\u0027s also simpler.\n\nBTW, I have a few concerns on these options, when the fifo tuning logic is disabled by default.\n- The fifo size should be large enough from the beginning, since it won\u0027t be increased. I suppose that a chunk as large as the (initial) fifo size is allocated at the fifo initialization. So this may increase the average in-used size of each fifo.\n- The utilization of this large fifo with a single large chunk (in many cases) may kept very low in the not-so-active connection (e.g. HTTP uplink connection).\n\nIt would be resolved if we call `fs_try_alloc_fifo ()` with minimum chunk size regardless the initial fifo size, although it would have a disadvantage that the average size of allocated chunks will be smaller.",
      "parentUuid": "27ccdd40_e3877b62",
      "range": {
        "startLine": 486,
        "startChar": 6,
        "endLine": 486,
        "endChar": 25
      },
      "revId": "ce0ca25a6c3139845ad45afd8af6bf130a9e3974",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "9a565c0d_26f0d66e",
        "filename": "src/vnet/session/session.c",
        "patchSetId": 10
      },
      "lineNbr": 486,
      "author": {
        "id": 193
      },
      "writtenOn": "2020-02-03T06:31:32Z",
      "side": 1,
      "message": "Hi Shibuya-san,\n\nAs the code stands now, rx notifications would be as frequent as session_fifo_tuning (since this is called when we deliver the rx notifications). And yes, option 2 looks simpler and would have the same effect, until we decide on the rest of the algorithm. My goal would be to get this under heavy testing as soon as possible since it\u0027s a major refactor, but also to keep on working on fine tuning in parallel. \n\nAs for the other issues\n- I already have a simple patch that initializes the fifo to a minimal chunk (4kB), instead of the full size, but I\u0027m still testing its performance impact. Not entirely sure why it sometimes leads to more drops and higher cpu consumption for the same throughput. Worst case we can make this configurable.\n- After the latest updates, fifos don\u0027t grow by more than max (len enqueued, f-\u003emin_alloc). Currently, min alloc is capped at 64kB (we may still fine tune this) and len for tcp enqueued is at most mss. So, at most we\u0027d waste 64kB, independent of how large fifo size is.",
      "parentUuid": "7f39afbb_af228ec4",
      "range": {
        "startLine": 486,
        "startChar": 6,
        "endLine": 486,
        "endChar": 25
      },
      "revId": "ce0ca25a6c3139845ad45afd8af6bf130a9e3974",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2",
      "unresolved": true
    }
  ]
}