{
  "comments": [
    {
      "key": {
        "uuid": "5e154b22_c898ea6d",
        "filename": "src/vnet/tcp/tcp_bt.c",
        "patchSetId": 1
      },
      "lineNbr": 293,
      "author": {
        "id": 1561
      },
      "writtenOn": "2020-10-22T01:51:34Z",
      "side": 1,
      "message": "This is an allocation of a new BTS, and I suspect that the `flags` can be uninitialized value. So the assignment here should be \"\u003d\", instead of \"|\u003d\", in my opinion.",
      "revId": "43b8f448b1f9718599e8585c507ce821bc1d31b8",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "56e20ea4_383f5d19",
        "filename": "src/vnet/tcp/tcp_bt.c",
        "patchSetId": 1
      },
      "lineNbr": 323,
      "author": {
        "id": 1561
      },
      "writtenOn": "2020-10-22T01:51:34Z",
      "side": 1,
      "message": "Before applying this change, the `tcp_bt_track_tx` extended the SACKED Tail-BTS with non-SACKED bytes. And (seemingly) it made the SACKED/non-SACKED management corrupted.",
      "revId": "43b8f448b1f9718599e8585c507ce821bc1d31b8",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "414fe3e1_2d6405c9",
        "filename": "src/vnet/tcp/tcp_output.c",
        "patchSetId": 1
      },
      "lineNbr": 1122,
      "author": {
        "id": 1561
      },
      "writtenOn": "2020-10-22T01:51:34Z",
      "side": 1,
      "message": "I see this condition plays a role to prevent duplicate/redundant calls of `session_add_self_custom_tx_evt`. However, I found that the custom_tx event is canceled by some reason, whereas the `tcp_session_custom_tx` is not really called, so that TCP_CONN_RXT_PENDING flag is eternally ON. If such a case happens, the `tcp_session_custom_tx` will never been called and the transaction would stall.\nSo commenting-out this if-condition is a temporary workaround for now. Fixing the underlying problem (that custom_tx event is silently canceled) should be the correct approach.",
      "revId": "43b8f448b1f9718599e8585c507ce821bc1d31b8",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "85775f28_c9ec6af6",
        "filename": "src/vnet/tcp/tcp_timer.h",
        "patchSetId": 1
      },
      "lineNbr": 98,
      "author": {
        "id": 1561
      },
      "writtenOn": "2020-10-22T01:51:34Z",
      "side": 1,
      "message": "The RACK specification defines that TLP (Tail Loss Probe) timer and REO (RACK REOrdering) timer have priority to RTO (Retransmit TimeOut) timer. So `tcp_retransmit_timer_set` should fail if either of TLP/REO timers is active.\nHowever, I suppose `tcp_retransmit_timer_force_update` should have priority than everything, so it is named \"force\". Right?",
      "revId": "43b8f448b1f9718599e8585c507ce821bc1d31b8",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "0a42637a_0d4f78f1",
        "filename": "src/vnet/tcp/tcp_types.h",
        "patchSetId": 1
      },
      "lineNbr": 126,
      "author": {
        "id": 1561
      },
      "writtenOn": "2020-10-22T01:51:34Z",
      "side": 1,
      "message": "In the current revision, RACK (byte-tracker based) and non-RACK (scoreboard based) are using a common TCP_CONN_FAST_RECOVERY flag. So the condition to express in-FastRecovery-by-RACK is not very intuitive: It is like `(tc-\u003erack.reordering_seen)`.\n\nI\u0027m thinking to add another flag TCP_CONN_RACK_RECOVERY. Then, it will be easier to manage the congestion state.",
      "revId": "43b8f448b1f9718599e8585c507ce821bc1d31b8",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2",
      "unresolved": true
    }
  ]
}