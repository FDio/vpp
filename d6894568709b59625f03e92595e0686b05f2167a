{
  "comments": [
    {
      "key": {
        "uuid": "a8546094_d132147a",
        "filename": "src/vnet/session/application_local.c",
        "patchSetId": 7
      },
      "lineNbr": 528,
      "author": {
        "id": 1263
      },
      "writtenOn": "2020-10-30T09:25:26Z",
      "side": 1,
      "message": "Rename the value to something like \"action count\", so you no longer need comments for any action different from \"packet sent\".",
      "range": {
        "startLine": 528,
        "startChar": 24,
        "endLine": 528,
        "endChar": 36
      },
      "revId": "d6894568709b59625f03e92595e0686b05f2167a",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "a5504171_d7269c82",
        "filename": "src/vnet/session/application_local.c",
        "patchSetId": 7
      },
      "lineNbr": 528,
      "author": {
        "id": 193
      },
      "writtenOn": "2020-10-30T15:08:09Z",
      "side": 1,
      "message": "Not sure I understand the comment. This function is called from the session scheduler which uses packets sent to limit work/dispatch. Other functions, e.g., handlers for tcp/udp, will return actual packets sent to the network but cut-through sessions do not generate packets (they don\u0027t interact with the network actually), instead they only pass notifications around in vpp. \n\nThe comment is meant to explain the 1, which we can tweak going forward in case we don\u0027t want to handle a max of 256 cut-through sessions/dispatch.",
      "parentUuid": "a8546094_d132147a",
      "range": {
        "startLine": 528,
        "startChar": 24,
        "endLine": 528,
        "endChar": 36
      },
      "revId": "d6894568709b59625f03e92595e0686b05f2167a",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "205314e6_613f7658",
        "filename": "src/vnet/session/application_local.c",
        "patchSetId": 7
      },
      "lineNbr": 528,
      "author": {
        "id": 1263
      },
      "writtenOn": "2020-10-30T16:06:40Z",
      "side": 1,
      "message": "\u003e the session scheduler which uses packets sent to limit work/dispatch.\n\nIt seems the limiting quantity is something more general than packets (directly) sent.\nI created a small edit to show what I mean: https://gerrit.fd.io/r/c/vpp/+/29700\nMaybe some of edited places should still refer to packets, but the return value is not one of them.\n\nNow I see this value directly affects the return value of function for node session_queue_node, and those (node function return values in general) probably already have a specific meaning attached already (I just do not know which documentation to consult yet).",
      "parentUuid": "a5504171_d7269c82",
      "range": {
        "startLine": 528,
        "startChar": 24,
        "endLine": 528,
        "endChar": 36
      },
      "revId": "d6894568709b59625f03e92595e0686b05f2167a",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "f9daa560_fc784874",
        "filename": "src/vnet/session/application_local.c",
        "patchSetId": 7
      },
      "lineNbr": 528,
      "author": {
        "id": 193
      },
      "writtenOn": "2020-10-30T16:15:35Z",
      "side": 1,
      "message": "That meaning is vectors (i.e, packets) generated. Yes it serves multiple purposes, as it will show up in show run as the number of vectors generated/dispatch. But as explained in the comment here, it also serves as a means of limiting total work/dispatch in the scheduler as it won\u0027t generate more than a max number of packets/dispatch (currently that value is a full vlib frame).",
      "parentUuid": "205314e6_613f7658",
      "range": {
        "startLine": 528,
        "startChar": 24,
        "endLine": 528,
        "endChar": 36
      },
      "revId": "d6894568709b59625f03e92595e0686b05f2167a",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "208fe564_aa7e0c52",
        "filename": "src/vnet/session/application_local.c",
        "patchSetId": 7
      },
      "lineNbr": 528,
      "author": {
        "id": 1263
      },
      "writtenOn": "2020-10-30T17:06:23Z",
      "side": 1,
      "message": "Together with [0] I gained a partial understanding. VPP processes vectors (called frames) of data units (called vectors, usually packets but can be anything). Node function return value is basically used only for bumping node \"vectors\" counter, as the graph algorithm decides how many vectors will subsequent nodes get to process. And tx nodes have no subsequent nodes.\nSome nodes (mainly input ones) are processing data from various outside sources. If they pass non-trivial data to subsequent nodes, their output size is limited by max frame size, which prevents them for spinning too long. But sometimes the data is trivial (just a notification that other thread has done its work). Maybe here it is worth to count those as vectors even if nothing is passed to subsequent nodes?\n\nsession_queue_node seems to be an input node which can also send packets (or process notifications). So those are not visible in the subsequent nodes, and we have freedom on how to count them. We could have two independent counters (one to show real vectors processed, one to prevent infinte loop), but it is nice to use a single counter for that, just so that \"vectors per call\" value tracks how busy the node was in a familiar way.\n\nI think the comment can say something along \"1 vector worth of work has been done\", which sounds less shady than \"make it look like we have sent something\".\n\n[0] https://gerrit.fd.io/r/c/vpp/+/29700/2#message-2804973058ef3d093efc78e4180386cdd0bcfb30",
      "parentUuid": "f9daa560_fc784874",
      "range": {
        "startLine": 528,
        "startChar": 24,
        "endLine": 528,
        "endChar": 36
      },
      "revId": "d6894568709b59625f03e92595e0686b05f2167a",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "87cdba32_3fa46fe8",
        "filename": "src/vnet/session/application_local.c",
        "patchSetId": 7
      },
      "lineNbr": 528,
      "author": {
        "id": 193
      },
      "writtenOn": "2020-10-30T17:48:09Z",
      "side": 1,
      "message": "Actually, what\u0027s reported in show run is the vectors/call, i.e. packets/call. A vlib frame can have up to 256 vectors. Now, notably, the session_node is not the average input or inner node in that it does more types of work. Specifically, for the point we\u0027re now excessively debating, it acts like a dispatcher for various types of transports and at one point the node needs to yield the cpu. So it needs feedback from those transport in terms of how much work they did. The unit we picked was packets because that\u0027s the first unit of work that was supported when this started (first transport added 4 years ago was tcp) but, as it can be gathered from this conversation, that doesn\u0027t cover all corner cases. Also, the total packets/dispatch are reported as work done by the node as a whole, but that\u0027s just stats. \n\nFinally, the comment is just a move of a previous comment, not a new one. Nonetheless, it pretty clearly states that 1) scheduler uses packet counts to bound work per dispatch 2) we make it look like we sent 1 packet (although we didn\u0027t). Not sure how that is shady.",
      "parentUuid": "208fe564_aa7e0c52",
      "range": {
        "startLine": 528,
        "startChar": 24,
        "endLine": 528,
        "endChar": 36
      },
      "revId": "d6894568709b59625f03e92595e0686b05f2167a",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "e941193e_dc1ca05c",
        "filename": "src/vnet/session/application_local.c",
        "patchSetId": 7
      },
      "lineNbr": 528,
      "author": {
        "id": 1263
      },
      "writtenOn": "2020-10-30T18:24:15Z",
      "side": 1,
      "message": "\u003e session_node is not the average input or inner node in that it does more types of work.\n\nMaybe it should be split into several nodes. Instruction caching will probably improve, and it would be more clear what unit of work (vector) is being processed, and how.\nI guess in ct_custom_tx, \"vector\" equals \"io event\".\n\n\u003e Finally, the comment is just a move of a previous comment, not a new one.\n\nFair, sorry if I am too distracting with my questions.\n\n\u003e scheduler uses packet counts to bound work per dispatch\n\nNow I understand \"scheduler\" here means not the general graph scheduler, but the loop (or two) in session_queue_node_fn.\n(One more reason to split the node, so scheduling is done by the graph scheduler.)\n\n\u003e The unit we picked was packets ...\n\u003e ... that doesn\u0027t cover all corner cases.\n\u003e Not sure how that is shady.\n\n\"make it look like\" is faking, which is shady in general.\nIn this case it perhaps is not shady, as we understand \"packet sent\" as a unit of work, not necessarily a literal packet being sent by the function.\n\nBut I agree, for now it is not worth renaming \"packet count\" to \"action count\" nor \"vector count\" here.",
      "parentUuid": "87cdba32_3fa46fe8",
      "range": {
        "startLine": 528,
        "startChar": 24,
        "endLine": 528,
        "endChar": 36
      },
      "revId": "d6894568709b59625f03e92595e0686b05f2167a",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2",
      "unresolved": true
    }
  ]
}