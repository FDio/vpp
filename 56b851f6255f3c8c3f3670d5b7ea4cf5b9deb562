{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "ff3a6728_0a4e6ed9",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1849
      },
      "writtenOn": "2022-10-24T09:27:12Z",
      "side": 1,
      "message": "Hi Gabriel, can you provide more detail about when and how segfault happens?\n",
      "revId": "56b851f6255f3c8c3f3670d5b7ea4cf5b9deb562",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "508b0d21_f907ed7b",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 2479
      },
      "writtenOn": "2022-10-24T12:02:33Z",
      "side": 1,
      "message": "This sefgault occurs when VPP have 10k tunnels for wireguard and VPP received packets and try do handshake process for each peers.\nThe main thread do handshake process and other can do lookup on the same array. \n\nBacktrace when the segfault occured: \n(Thread 4 received wg packets, Thread 1 - main thread)\n\nThread 4 (Thread 0x7ffaf1b87700 (LWP 599557)):\n#0  0x00007ffff62e15e9 in hash_is_user (v\u003d0x7ffc0502e3c8, i\u003d13021) at /opt/networking.dataplane.fdio.vpp/src/vppinfra/hash.h:128\n#1  lookup (v\u003d0x7ffc0502e3c8, key\u003d\u003coptimized out\u003e, op\u003d\u003coptimized out\u003e, new_value\u003d0x0, old_value\u003d0x0) at /opt/networking.dataplane.fdio.vpp/src/vppinfra/hash.c:375\n#2  0x00007ffff62e1357 in _hash_get (v\u003d0x7ffc0502e3c8, key\u003d16385323528908460640) at /opt/networking.dataplane.fdio.vpp/src/vppinfra/hash.c:455\n#3  0x00007ffbf2b1e71d in wg_index_table_lookup (table\u003d\u003coptimized out\u003e, key\u003d\u003coptimized out\u003e) at /opt/networking.dataplane.fdio.vpp/src/plugins/wireguard/wireguard_index_table.c:81\n#4  0x00007ffbf2b06b9d in wg_input_inline (vm\u003d\u003coptimized out\u003e, node\u003d\u003coptimized out\u003e, frame\u003d\u003coptimized out\u003e, is_ip4\u003d\u003coptimized out\u003e, async_next_node\u003d\u003coptimized out\u003e) at /opt/networking.dataplane.fdio.vpp/src/plugins/wireguard/wireguard_input.c:836\n#5  wg4_input_node_fn (vm\u003d\u003coptimized out\u003e, node\u003d\u003coptimized out\u003e, frame\u003d\u003coptimized out\u003e) at /opt/networking.dataplane.fdio.vpp/src/plugins/wireguard/wireguard_input.c:1047\n#6  0x00007ffff63de6fb in dispatch_node (vm\u003d0x7ffc02425280, node\u003d0x7ffc0260f180, type\u003dVLIB_NODE_TYPE_INTERNAL, dispatch_state\u003dVLIB_NODE_STATE_POLLING, frame\u003d\u003coptimized out\u003e, last_time_stamp\u003d33059441763356988) at /opt/networking.dataplane.fdio.vpp/src/vlib/main.c:960\n#7  dispatch_pending_node (vm\u003d0x7ffc02425280, pending_frame_index\u003d5, last_time_stamp\u003d33059441763356988) at /opt/networking.dataplane.fdio.vpp/src/vlib/main.c:1119\n#8  vlib_main_or_worker_loop (vm\u003d0x7ffc02425280, is_main\u003d0) at /opt/networking.dataplane.fdio.vpp/src/vlib/main.c:1588\n#9  vlib_worker_loop (vm\u003d0x7ffc02425280) at /opt/networking.dataplane.fdio.vpp/src/vlib/main.c:1722\n#10 0x00007ffff6430afa in vlib_worker_thread_fn (arg\u003d0x7ffbf7defbc0) at /opt/networking.dataplane.fdio.vpp/src/vlib/threads.c:1598\n#11 0x00007ffff642ae01 in vlib_worker_thread_bootstrap_fn (arg\u003d0x7ffbf7defbc0) at /opt/networking.dataplane.fdio.vpp/src/vlib/threads.c:418\n#12 0x00007ffff6359609 in start_thread (arg\u003d\u003coptimized out\u003e) at pthread_create.c:477\n#13 0x00007ffff6094133 in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95\n\nThread 1 (Thread 0x7ffff5f73c40 (LWP 599551)):\n#0  clib_time_now_internal (c\u003d0x7ffbf5f73700, n\u003d33059441801349710) at /opt/networking.dataplane.fdio.vpp/src/vppinfra/time.h:228\n#1  clib_time_now (c\u003d0x7ffbf5f73700) at /opt/networking.dataplane.fdio.vpp/src/vppinfra/time.h:241\n#2  vlib_time_now (vm\u003d0x7ffbf5f73700) at /opt/networking.dataplane.fdio.vpp/src/vlib/main.h:333\n#3  vlib_worker_thread_barrier_sync_int (vm\u003d0x7ffbf5f73700, func_name\u003d\u003coptimized out\u003e) at /opt/networking.dataplane.fdio.vpp/src/vlib/threads.c:1367\n#4  0x00007ffff7fb1934 in vl_api_rpc_call_main_thread_inline (fp\u003d\u003coptimized out\u003e, data\u003d\u003coptimized out\u003e, data_length\u003d\u003coptimized out\u003e, force_rpc\u003d0 \u0027\\000\u0027) at /opt/networking.dataplane.fdio.vpp/src/vlibmemory/memclnt_api.c:604\n#5  vl_api_rpc_call_main_thread (fp\u003d0x7ffbf2b1d550 \u003cstart_timer_thread_fn\u003e, data\u003d0x7ffbf2eaece0 \"\\325\\005\", data_length\u003d12) at /opt/networking.dataplane.fdio.vpp/src/vlibmemory/memclnt_api.c:638\n#6  0x00007ffbf2b1c13f in start_timer_from_mt (peer_idx\u003d\u003coptimized out\u003e, timer_id\u003d0, interval_ticks\u003d\u003coptimized out\u003e) at /opt/networking.dataplane.fdio.vpp/src/plugins/wireguard/wireguard_timer.c:87\n#7  wg_timers_handshake_initiated (peer\u003d\u003coptimized out\u003e) at /opt/networking.dataplane.fdio.vpp/src/plugins/wireguard/wireguard_timer.c:237\n#8  0x00007ffbf2b16cad in wg_send_handshake (vm\u003d0x7ffbf5f73700, peer\u003d0x7ffc0c8c0558, is_retry\u003d\u003coptimized out\u003e) at /opt/networking.dataplane.fdio.vpp/src/plugins/wireguard/wireguard_send.c:178\n#9  0x00007ffbf2b1cb1f in wg_expired_retransmit_handshake (vm\u003d0x7ffbf5f73700, peer\u003d\u003coptimized out\u003e) at /opt/networking.dataplane.fdio.vpp/src/plugins/wireguard/wireguard_timer.c:128\n#10 expired_timer_callback (expired_timers\u003d0x7ffc0636fb28) at /opt/networking.dataplane.fdio.vpp/src/plugins/wireguard/wireguard_timer.c:344\n#11 0x00007ffff631c7b9 in tw_timer_expire_timers_internal_16t_2w_512sl (tw\u003d\u003coptimized out\u003e, now\u003d\u003coptimized out\u003e, callback_vector_arg\u003d\u003coptimized out\u003e) at /opt/networking.dataplane.fdio.vpp/src/vppinfra/tw_timer_template.c:776\n#12 0x00007ffff631c2f4 in tw_timer_expire_timers_16t_2w_512sl (tw\u003d0x0, now\u003d1056106536) at /opt/networking.dataplane.fdio.vpp/src/vppinfra/tw_timer_template.c:817\n#13 0x00007ffbf2b1de72 in wg_timer_mngr_fn (vm\u003d0x7ffbf5f73700, rt\u003d\u003coptimized out\u003e, f\u003d\u003coptimized out\u003e) at /opt/networking.dataplane.fdio.vpp/src/plugins/wireguard/wireguard_timer.c:406\n#14 0x00007ffff63e4837 in vlib_process_bootstrap (_a\u003d\u003coptimized out\u003e) at /opt/networking.dataplane.fdio.vpp/src/vlib/main.c:1221\n#15 0x00007ffff62e96a8 in clib_calljmp () at /opt/networking.dataplane.fdio.vpp/src/vppinfra/longjmp.S:123\n#16 0x00007ffbf2afad60 in ?? ()\n#17 0x00007ffff63dc3d0 in vlib_process_startup (vm\u003d0x7ffbf5f73700, p\u003d0x7ffbf786ad00, f\u003d0x0) at /opt/networking.dataplane.fdio.vpp/src/vlib/main.c:1246\n#18 dispatch_process (vm\u003d0x7ffbf5f73700, p\u003d0x7ffbf786ad00, f\u003d0x0, last_time_stamp\u003d\u003coptimized out\u003e) at /opt/networking.dataplane.fdio.vpp/src/vlib/main.c:1302",
      "parentUuid": "ff3a6728_0a4e6ed9",
      "revId": "56b851f6255f3c8c3f3670d5b7ea4cf5b9deb562",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "95f4a3e6_63a0bb30",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1849
      },
      "writtenOn": "2022-10-25T08:29:56Z",
      "side": 1,
      "message": "The fix looks good to me - it is always nice to minimize the read of shared memory between threads to avoid inconsistent data as well as attacks.",
      "revId": "56b851f6255f3c8c3f3670d5b7ea4cf5b9deb562",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "f80fe4b5_dbcb17ae",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1849
      },
      "writtenOn": "2022-10-25T08:29:56Z",
      "side": 1,
      "message": "Thanks a million.",
      "parentUuid": "508b0d21_f907ed7b",
      "revId": "56b851f6255f3c8c3f3670d5b7ea4cf5b9deb562",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2"
    }
  ]
}