{
  "comments": [
    {
      "key": {
        "uuid": "986cb73d_5e9f7acd",
        "filename": "src/svm/svm_fifo.c",
        "patchSetId": 46
      },
      "lineNbr": 380,
      "author": {
        "id": 1561
      },
      "writtenOn": "2020-01-16T14:46:45Z",
      "side": 1,
      "message": "Hi Florin,\nIs this ASSERT still valid, whereas we may decrease f-\u003esize regardless of the actual size?",
      "revId": "eda759eb6934a821097ec0511ec2df2821c18f58",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "8ffa2e3b_793112e9",
        "filename": "src/svm/svm_fifo.c",
        "patchSetId": 46
      },
      "lineNbr": 380,
      "author": {
        "id": 193
      },
      "writtenOn": "2020-01-16T15:23:02Z",
      "side": 1,
      "message": "I think it still is. That is, we shouldn\u0027t have more out-of-order data than the full size of the fifo. And although we can reduce the size of the fifo externally, we shouldn\u0027t reduce it to a point where it covers less than the amount of data written. \n\nAre you thinking that it may be too loose or too strict?",
      "parentUuid": "986cb73d_5e9f7acd",
      "revId": "eda759eb6934a821097ec0511ec2df2821c18f58",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "6b5b25e3_e3fd863a",
        "filename": "src/svm/svm_fifo.c",
        "patchSetId": 46
      },
      "lineNbr": 380,
      "author": {
        "id": 1561
      },
      "writtenOn": "2020-01-16T15:43:29Z",
      "side": 1,
      "message": "At this moment I\u0027m using a tentative simple fifo-tuning-logic which would increase or decrease f-\u003esize per certain conditions, just to do some functional tests. Then I see this ASSERT hits frequently.\nIf this ASSERT is valid, fifo-tuning-logic needs to be careful about the limit of reduction.",
      "parentUuid": "8ffa2e3b_793112e9",
      "revId": "eda759eb6934a821097ec0511ec2df2821c18f58",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "6c2c8ae5_81cac8af",
        "filename": "src/svm/svm_fifo.c",
        "patchSetId": 46
      },
      "lineNbr": 380,
      "author": {
        "id": 193
      },
      "writtenOn": "2020-01-16T15:56:57Z",
      "side": 1,
      "message": "Hm. I believe size reduction should always ensure that head + f-\u003esize is more than the last byte written out-of-order. \n\nThat\u0027s why the best way to reduce fifo size would be after a dequeue because reducing the size by the amount of bytes dequeued would have no impact (head + f-\u003esize)",
      "parentUuid": "6b5b25e3_e3fd863a",
      "revId": "eda759eb6934a821097ec0511ec2df2821c18f58",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "fcbeba17_f70f1d0e",
        "filename": "src/svm/svm_fifo.c",
        "patchSetId": 46
      },
      "lineNbr": 380,
      "author": {
        "id": 1561
      },
      "writtenOn": "2020-01-16T17:17:42Z",
      "side": 1,
      "message": "Got it. Thanks.",
      "parentUuid": "6c2c8ae5_81cac8af",
      "revId": "eda759eb6934a821097ec0511ec2df2821c18f58",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1de9f6a9_88cec139",
        "filename": "src/svm/svm_fifo.c",
        "patchSetId": 46
      },
      "lineNbr": 1047,
      "author": {
        "id": 1561
      },
      "writtenOn": "2020-01-20T11:01:27Z",
      "side": 1,
      "message": "During a test, I see a problem with the following condition:\n  f-\u003eooo_deq-\u003estart_byte \u003c head_idx \u003c (f-\u003eooo_deq-\u003estart_byte + f-\u003eooo_deq-\u003elength)\n  (f-\u003eooo_deq-\u003estart_byte + f-\u003eooo_deq-\u003elength) \u003c (head_idx + len)\n  f-\u003eooo_deq-\u003enext \u003d\u003d 0\nThis caused SEGV in svm_fifo_copy_from_chunk_ma_avx2(), in the iteration with c\u003dc-\u003enext.\n\nDoes it suggest some condition-check is needed here?\n(It might have happened that I made a mistake with the patch merge, if you have already addressed this condition. I\u0027m not testing your patch purely.)",
      "revId": "eda759eb6934a821097ec0511ec2df2821c18f58",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "ab262d7b_27fbf4fd",
        "filename": "src/svm/svm_fifo.c",
        "patchSetId": 46
      },
      "lineNbr": 1047,
      "author": {
        "id": 193
      },
      "writtenOn": "2020-01-20T15:55:36Z",
      "side": 1,
      "message": "Not sure. I\u0027ve been testing with this and pushing 37Gbps for 10 or more seconds without issue. \n\nAre you sure the test is sane? Meaning, are you exercising the fifo through the expected apis? If yes, could you point me to the test?",
      "parentUuid": "1de9f6a9_88cec139",
      "revId": "eda759eb6934a821097ec0511ec2df2821c18f58",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "a1ad8094_41299307",
        "filename": "src/svm/svm_fifo.c",
        "patchSetId": 46
      },
      "lineNbr": 1047,
      "author": {
        "id": 1561
      },
      "writtenOn": "2020-01-20T17:02:51Z",
      "side": 1,
      "message": "I was trying to cause some memory pressure (i.e. small segment size, and rate-limited clients) with the hs_apps/proxy and saw this.",
      "parentUuid": "ab262d7b_27fbf4fd",
      "revId": "eda759eb6934a821097ec0511ec2df2821c18f58",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "d2b5c09e_cad8f8cf",
        "filename": "src/svm/svm_fifo.c",
        "patchSetId": 46
      },
      "lineNbr": 1047,
      "author": {
        "id": 193
      },
      "writtenOn": "2020-01-20T17:28:22Z",
      "side": 1,
      "message": "This might be something different. I haven\u0027t tested with the proxy app. I suspect this might be related to the fact that you\u0027re doing both ooo writes and reads to the same chunk. We have only one rbtree index in the chunk and that may lead to collisions. So we may end up needing an ooo_enq and ooo_deq index. \n\nWill try to reproduce this.",
      "parentUuid": "a1ad8094_41299307",
      "revId": "eda759eb6934a821097ec0511ec2df2821c18f58",
      "serverId": "6d2eb258-4fe2-443e-8a38-ca81da23d4c2",
      "unresolved": true
    }
  ]
}